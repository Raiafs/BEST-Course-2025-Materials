{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1108a357",
   "metadata": {},
   "source": [
    "## Voice Signal Analysis and Feature Extraction\n",
    "\n",
    "In this notebook, you will explore and extract meaningful features from Voice signals from the temporal and spectral domain.\n",
    "This task will be performed using the common librarie for these tasks, OpenSMILE.\n",
    "\n",
    "To get started, install heartpy and neurokit2. To do it, you can run the following command on the vscode terminal.\n",
    "- pip install opensmile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opensmile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd864c6c",
   "metadata": {},
   "source": [
    "### Features Extraction\n",
    "\n",
    "To extract the features of voice, we use libraries such as OpenSMILE.\n",
    "This library has multiple feature sets that we can use by ourselves. In this example, we are using the GeMAPS feature set, a commonly used set with lots of features, such as f0, jitter and shimmer.\n",
    "The feature level should stay as functionals, since the other levels use frame-level resolution, creating a feature matrix, not vector.\n",
    "\n",
    "In the extraction below, we work as follows:\n",
    "1. create the OpenSMILE processor with GeMAPS.\n",
    "2. define the selected features we want to extract. You can find in the end of this notebook code that you can run to read the features avaliable on GeMAPS or search it on the internet.\n",
    "3. select only the features selected from the entire feature set\n",
    "4. return a tuple containing the features selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb6ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_path: str) -> tuple|None:\n",
    "    \"\"\"\n",
    "    Extracts F0, jitter, and shimmer features from an audio file.\n",
    "\n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        tuple of features selected.\n",
    "    \"\"\"\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=opensmile.FeatureSet.GeMAPSv01b,\n",
    "        feature_level=opensmile.FeatureLevel.Functionals\n",
    "    )\n",
    "\n",
    "    selected_features = [\n",
    "        'F0semitoneFrom27.5Hz_sma3_amean',\n",
    "        'F0semitoneFrom27.5Hz_sma3_stddevNorm',\n",
    "        'F0semitoneFrom27.5Hz_sma3_quartile2',\n",
    "        'jitterLocal_sma3_amean',\n",
    "        'shimmerLocaldB_sma3_amean'\n",
    "    ]\n",
    "    try:\n",
    "        features = smile.process_file(audio_path)\n",
    "        \n",
    "        selected = features[selected_features]\n",
    "        \n",
    "        return tuple(selected.iloc[0].values.tolist())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1d3c6",
   "metadata": {},
   "source": [
    "### OpenSMILE structure\n",
    "\n",
    "OpenSMILE has a lot of comprehensible feature sets to extract from an audio, so feel free to explore them.\n",
    "The feature_set variable defines which set you can use. these go from GeMAPS (a popular one with features like F0, jitter and shimmer).\n",
    "The feature_level is the way the feature set will be exposed.\n",
    "- LowLevelDescriptors for Frame-level (e.g., every 10ms). Useful for signal modeling or speech segmentation\n",
    "- LowLevelDescriptors_Delta\tfor Frame-level plus deltas (first derivative)\n",
    "- Functionals for Aggregated over the whole file (mean, std, min, etc.). Best for classification.\n",
    "\n",
    "Keep in mind that to use frame-level features, you'll have to take into consideration time as well, so for simplicity, you should avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.GeMAPSv01b,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals\n",
    ")\n",
    "\n",
    "audio_path = os.path.join(os.getcwd(), \"common_voice_ka_21298144.mp3\")\n",
    "\n",
    "# Extract features\n",
    "features_df = smile.process_file(audio_path)\n",
    "\n",
    "# Print type and shape of the output\n",
    "print(f\"Type of output: {type(features_df)}\")\n",
    "print(f\"Shape of output: {features_df.shape}\")\n",
    "\n",
    "# The output is a pandas DataFrame with one row and many columns\n",
    "print(\"\\nColumns (feature names):\")\n",
    "print(features_df.columns)\n",
    "\n",
    "print(\"\\nPreview of feature values:\")\n",
    "print(features_df.head())\n",
    "\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(features_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
